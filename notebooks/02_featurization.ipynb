{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55ed1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Serving model eos4wt0: morgan-fps\n",
      "\n",
      "   URL: http://0.0.0.0:54907\n",
      "   PID: -1\n",
      "   SRV: pulled_docker\n",
      "   Output source: local-only\n",
      "\n",
      "ðŸ‘‰ To run model:\n",
      "   - run\n",
      "\n",
      "ðŸ’ Information:\n",
      "   - info\n",
      "â›” Model eos4wt0 closed\n",
      "ðŸš€ Serving model eos4wt0: morgan-fps\n",
      "\n",
      "   URL: http://0.0.0.0:45549\n",
      "   PID: -1\n",
      "   SRV: pulled_docker\n",
      "   Output source: local-only\n",
      "\n",
      "ðŸ‘‰ To run model:\n",
      "   - run\n",
      "\n",
      "ðŸ’ Information:\n",
      "   - info\n",
      "â›” Model eos4wt0 closed\n",
      "ðŸš€ Serving model eos4wt0: morgan-fps\n",
      "\n",
      "   URL: http://0.0.0.0:40511\n",
      "   PID: -1\n",
      "   SRV: pulled_docker\n",
      "   Output source: local-only\n",
      "\n",
      "ðŸ‘‰ To run model:\n",
      "   - run\n",
      "\n",
      "ðŸ’ Information:\n",
      "   - info\n",
      "â›” Model eos4wt0 closed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (332)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m valid_features \u001b[38;5;241m=\u001b[39m featurize_smiles(valid_smiles)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Add features to the DataFrames\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_features\n\u001b[1;32m     62\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_features\n\u001b[1;32m     63\u001b[0m valid_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m valid_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (332)"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"../data\"\n",
    "train_file = os.path.join(data_dir, \"dili_train.csv\")\n",
    "test_file = os.path.join(data_dir, \"dili_test.csv\")\n",
    "valid_file = os.path.join(data_dir, \"dili_valid.csv\")\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "valid_df = pd.read_csv(valid_file)\n",
    "\n",
    "# Function to featurize SMILES using Ersilia model eos4wt0\n",
    "def featurize_smiles(smiles_list, model_id=\"eos4wt0\"):\n",
    "    # Start the Ersilia service\n",
    "    subprocess.run([\"ersilia\", \"serve\", model_id], check=True)\n",
    "    \n",
    "    # Prepare a temporary file with SMILES strings\n",
    "    with open(\"temp_smiles.txt\", \"w\") as f:\n",
    "        for smiles in smiles_list:\n",
    "            f.write(smiles + \"\\n\")\n",
    "    \n",
    "    # Run Ersilia to get Morgan Fingerprints\n",
    "    result = subprocess.run(\n",
    "        [\"ersilia\", \"-v\", \"run\", \"-i\", \"temp_smiles.txt\"],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    # Parse the output\n",
    "    output_lines = result.stdout.splitlines()\n",
    "    features = []\n",
    "    for line in output_lines:\n",
    "        try:\n",
    "            result_dict = json.loads(line)\n",
    "            feature_vector = result_dict[\"output\"][\"outcome\"]\n",
    "            features.append(feature_vector)\n",
    "        except:\n",
    "            features.append(None)  # Handle any errors \n",
    "    \n",
    "    # Stop the Ersilia service\n",
    "    subprocess.run([\"ersilia\", \"close\"], check=True)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Featurize the SMILES strings for each dataset\n",
    "train_smiles = train_df['Drug'].tolist()\n",
    "test_smiles = test_df['Drug'].tolist()\n",
    "valid_smiles = valid_df['Drug'].tolist()\n",
    "\n",
    "train_features = featurize_smiles(train_smiles)\n",
    "test_features = featurize_smiles(test_smiles)\n",
    "valid_features = featurize_smiles(valid_smiles)\n",
    "\n",
    "# Add features to the DataFrames\n",
    "train_df['Features'] = train_features\n",
    "test_df['Features'] = test_features\n",
    "valid_df['Features'] = valid_df\n",
    "\n",
    "# Check for any failed featurizations\n",
    "print(\"Number of failed featurizations in training set:\", train_df['Features'].isnull().sum())\n",
    "print(\"Number of failed featurizations in test set:\", test_df['Features'].isnull().sum())\n",
    "print(\"Number of failed featurizations in validation set:\", valid_df['Features'].isnull().sum())\n",
    "\n",
    "# Drop rows with failed featurizations (if any)\n",
    "train_df = train_df.dropna(subset=['Features'])\n",
    "test_df = test_df.dropna(subset=['Features'])\n",
    "valid_df = valid_df.dropna(subset=['Features'])\n",
    "\n",
    "# Save the featurized datasets\n",
    "train_df.to_csv(os.path.join(data_dir, \"dili_train_featurized.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(data_dir, \"dili_test_featurized.csv\"), index=False)\n",
    "valid_df.to_csv(os.path.join(data_dir, \"dili_valid_featurized.csv\"), index=False)\n",
    "\n",
    "print(\"Featurized datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a95fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfd98f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
